{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0W_j6VEdbgt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77ll9it6d0EY",
        "outputId": "a2e93666-b5db-4d14-f295-50f85a9b7fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/GIGGLE/dataset.zip\"\n",
        "extract_dir = \"/content/drive/MyDrive/GIGGLE/behavior dataset\"\n",
        "\n",
        "# Unzipping the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"Dataset unzipped successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHfzrQ50enVu",
        "outputId": "9b268da9-ac5b-406d-c386-684528514fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset unzipped successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "-Af4_GRsforN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Parameters\n",
        "img_size = 128\n",
        "num_classes = 2\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Load dataset\n",
        "def load_dataset(dataset_path=\"/content/drive/MyDrive/GIGGLE/behavior dataset\"):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label, folder in enumerate([\"not_crossing\", \"crossing\"]):\n",
        "        folder_path = os.path.join(dataset_path, folder)\n",
        "        for filename in os.listdir(folder_path):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (img_size, img_size))\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    images = np.array(images, dtype=np.float32) / 255.0  # Normalize images\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Load data\n",
        "images, labels = load_dataset()\n",
        "\n",
        "# Split into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_val = to_categorical(y_val, num_classes)\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Define CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=len(X_train) // batch_size,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate model\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation accuracy: {val_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "aMV4KoqledRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"/content/drive/MyDrive/GIGGLE/behavior dataset/crossing_classifier.h5\")\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6y2g2vXfsXV",
        "outputId": "598bd049-39fa-41a7-c2ce-699934b92ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "loaded_model = load_model(\"/content/drive/MyDrive/GIGGLE/behavior dataset/crossing_classifier.h5\")\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R05vpKASf4vb",
        "outputId": "b908df1e-d041-4f3d-8a81-c3931194394a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image_path, model, img_size=128):\n",
        "    # Load and preprocess the image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255.0  # Normalize pixel values\n",
        "\n",
        "    # Predict using the model\n",
        "    prediction = model.predict(img)\n",
        "    predicted_label = np.argmax(prediction)\n",
        "\n",
        "    # Return the result\n",
        "    return \"Crossing\" if predicted_label == 1 else \"Not Crossing\"\n",
        "\n",
        "# Test prediction on a new image\n",
        "image_path = \"/content/drive/MyDrive/GIGGLE/Test/test1.jpg\"\n",
        "result = predict_image(image_path, loaded_model)\n",
        "print(f\"Prediction: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIog_sMwgKaM",
        "outputId": "26680e2c-0a2e-43a5-b9a2-9dee741eafe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step\n",
            "Prediction: Not Crossing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/GIGGLE/Test/test 2.jpg\"\n",
        "result = predict_image(image_path, loaded_model)\n",
        "print(f\"Prediction: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJW6ml3yhISY",
        "outputId": "05ae8dad-ad32-4bb7-8ce6-7d7dbb6dc9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Prediction: Crossing\n"
          ]
        }
      ]
    }
  ]
}