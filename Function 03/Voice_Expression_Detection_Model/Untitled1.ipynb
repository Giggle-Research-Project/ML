{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22522e59-4d7f-4da5-a5e6-5e530f5891a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">897</span> │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ multi_head_attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_1 (\u001b[38;5;33mAny\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m897\u001b[0m │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m2\u001b[0m │ multi_head_attention_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │           \u001b[38;5;34m1,032\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,004</span> (394.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,004\u001b[0m (394.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,004</span> (394.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,004\u001b[0m (394.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step\n",
      "Sample output shape (emotion): (2, 8)\n",
      "Sample output shape (confidence): (2, 1)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\140095176.py\", line 95, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 6 3 7 1 0 2 1 2 1 4 6 1 3 2 2 3 0 6 6 0 3 5 2 3 3 3 3 2 4 0 1 6\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_11815]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample output shape (confidence):\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_output[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# **Step 4: Train the Model**\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_val\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[0;32m    100\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# **Step 5: Evaluate the Model**\u001b[39;00m\n\u001b[0;32m    103\u001b[0m test_loss, test_metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    104\u001b[0m     X_test, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: conf_test}\n\u001b[0;32m    105\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\140095176.py\", line 95, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 6 3 7 1 0 2 1 2 1 4 6 1 3 2 2 3 0 6 6 0 3 5 2 3 3 3 3 2 4 0 1 6\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_11815]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# **Step 1: Data Preprocessing**\n",
    "DATA_PATH = \"C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/\"\n",
    "\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    return np.hstack([mfccs.mean(axis=1), chroma.mean(axis=1), spectral_contrast.mean(axis=1)])\n",
    "\n",
    "def parse_emotion_from_filename(filename):\n",
    "    parts = filename.split('-')\n",
    "    emotion_code = int(parts[2])  # Extract emotion code\n",
    "    return emotion_code - 1  # Map to zero-based index\n",
    "\n",
    "def generate_confidence(label):\n",
    "    confidence_map = {0: 0.9, 1: 0.8, 2: 0.85, 3: 0.7, 4: 0.95, 5: 0.75, 6: 0.88, 7: 0.92}\n",
    "    return confidence_map.get(label, 0.8)\n",
    "\n",
    "data = []\n",
    "for actor_folder in os.listdir(DATA_PATH):\n",
    "    folder_path = os.path.join(DATA_PATH, actor_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                features = extract_features(file_path)\n",
    "                label = parse_emotion_from_filename(file)\n",
    "                confidence = generate_confidence(label)\n",
    "                data.append((features, label, confidence))\n",
    "\n",
    "features_df = pd.DataFrame(data, columns=[\"features\", \"label\", \"confidence\"])\n",
    "\n",
    "X = np.array(features_df[\"features\"].tolist())\n",
    "y = np.array(features_df[\"label\"].tolist())\n",
    "confidence = np.array(features_df[\"confidence\"].tolist())\n",
    "\n",
    "num_classes = 8\n",
    "assert np.all((y >= 0) & (y < num_classes)), \"Labels must be in range [0, 7]\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp, conf_train, conf_temp = train_test_split(\n",
    "    X, y, confidence, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test, conf_val, conf_test = train_test_split(\n",
    "    X_temp, y_temp, conf_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "conf_train = conf_train.reshape(-1, 1)\n",
    "conf_val = conf_val.reshape(-1, 1)\n",
    "conf_test = conf_test.reshape(-1, 1)\n",
    "\n",
    "# **Step 2: Model Definition**\n",
    "def build_transformer_lstm(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Masking()(inputs)\n",
    "    x = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.LSTM(128)(x)\n",
    "    emotion_output = layers.Dense(num_classes, activation=\"softmax\", name=\"emotion_output\")(x)\n",
    "    confidence_output = layers.Dense(1, activation=\"sigmoid\", name=\"confidence_output\")(x)\n",
    "    return models.Model(inputs, [emotion_output, confidence_output])\n",
    "\n",
    "model = build_transformer_lstm((X_train.shape[1], 1), num_classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\"emotion_output\": \"sparse_categorical_crossentropy\", \"confidence_output\": \"mse\"},\n",
    "    metrics={\"emotion_output\": \"accuracy\"}\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# **Step 3: Verify Before Training**\n",
    "sample_input = X_train[:2]\n",
    "sample_output = model.predict(sample_input)\n",
    "print(\"Sample output shape (emotion):\", sample_output[0].shape)\n",
    "print(\"Sample output shape (confidence):\", sample_output[1].shape)\n",
    "\n",
    "# **Step 4: Train the Model**\n",
    "history = model.fit(\n",
    "    X_train, {\"emotion_output\": y_train, \"confidence_output\": conf_train},\n",
    "    validation_data=(X_val, {\"emotion_output\": y_val, \"confidence_output\": conf_val}),\n",
    "    epochs=30,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# **Step 5: Evaluate the Model**\n",
    "test_loss, test_metrics = model.evaluate(\n",
    "    X_test, {\"emotion_output\": y_test, \"confidence_output\": conf_test}\n",
    ")\n",
    "\n",
    "print(f\"Emotion Test Accuracy: {test_metrics[1] * 100:.2f}%\")\n",
    "print(f\"Confidence Test MSE: {test_loss[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b1dc91-ece9-4673-b967-b093b45373fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in dataset: [0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in dataset:\", np.unique(y_train))\n",
    "assert np.all((y_train >= 0) & (y_train < num_classes)), \"Labels must be in range [0, 7]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab56a3b-17bd-4eb3-8592-a138e2435701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training data: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in validation data: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in test data: [0 1 2 3 4 5 6 7]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Sample output shape (emotion): (2, 8)\n",
      "Sample output shape (confidence): (2, 1)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\140095176.py\", line 95, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 5 4 7 4 0 6 3 2 1 3 5 4 7 3 5 3 6 3 3 7 7 1 5 2 2 6 5 5 4 0 4 3\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_11815]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample output shape (confidence):\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_output[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Expect (2, 1)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_val\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m test_loss, test_metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m     28\u001b[0m     X_test, \n\u001b[0;32m     29\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: conf_test}\n\u001b[0;32m     30\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\140095176.py\", line 95, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 5 4 7 4 0 6 3 2 1 3 5 4 7 3 5 3 6 3 3 7 7 1 5 2 2 6 5 5 4 0 4 3\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_11815]"
     ]
    }
   ],
   "source": [
    "# Validate labels\n",
    "print(\"Unique labels in training data:\", np.unique(y_train))\n",
    "print(\"Unique labels in validation data:\", np.unique(y_val))\n",
    "print(\"Unique labels in test data:\", np.unique(y_test))\n",
    "\n",
    "assert np.all((y_train >= 0) & (y_train < num_classes)), \"Train labels out of range [0, 7]\"\n",
    "assert np.all((y_val >= 0) & (y_val < num_classes)), \"Validation labels out of range [0, 7]\"\n",
    "assert np.all((y_test >= 0) & (y_test < num_classes)), \"Test labels out of range [0, 7]\"\n",
    "\n",
    "# Confirm model output compatibility\n",
    "sample_input = X_train[:2]\n",
    "sample_output = model.predict(sample_input)\n",
    "print(\"Sample output shape (emotion):\", sample_output[0].shape)  # Expect (2, 8)\n",
    "print(\"Sample output shape (confidence):\", sample_output[1].shape)  # Expect (2, 1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    {\"emotion_output\": y_train, \"confidence_output\": conf_train},\n",
    "    validation_data=(X_val, {\"emotion_output\": y_val, \"confidence_output\": conf_val}),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_metrics = model.evaluate(\n",
    "    X_test, \n",
    "    {\"emotion_output\": y_test, \"confidence_output\": conf_test}\n",
    ")\n",
    "print(f\"Emotion Test Accuracy: {test_metrics[1] * 100:.2f}%\")\n",
    "print(f\"Confidence Test MSE: {test_loss[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce0358f-44e3-4302-8a83-6532e37218e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │ masking_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ masking_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ any_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ multi_head_attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_2 (\u001b[38;5;33mNotEqual\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_2 (\u001b[38;5;33mMasking\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_2 (\u001b[38;5;33mAny\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │              \u001b[38;5;34m15\u001b[0m │ masking_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ masking_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ any_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m2\u001b[0m │ multi_head_attention_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │           \u001b[38;5;34m1,032\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,122</span> (391.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,122\u001b[0m (391.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,122</span> (391.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,122\u001b[0m (391.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Model\n",
    "input_layer = tf.keras.layers.Input(shape=(59, 1), name=\"input_layer\")\n",
    "x = tf.keras.layers.Masking(mask_value=0)(input_layer)\n",
    "x = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=1)(x, x)\n",
    "x = tf.keras.layers.LayerNormalization()(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "lstm_output = tf.keras.layers.LSTM(128)(x)\n",
    "\n",
    "# Emotion detection output\n",
    "emotion_output = tf.keras.layers.Dense(8, activation=\"softmax\", name=\"emotion_output\")(lstm_output)\n",
    "\n",
    "# Confidence level output\n",
    "confidence_output = tf.keras.layers.Dense(1, activation=\"linear\", name=\"confidence_output\")(lstm_output)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=[emotion_output, confidence_output])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"emotion_output\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        \"confidence_output\": tf.keras.losses.MeanSquaredError()\n",
    "    },\n",
    "    metrics={\n",
    "        \"emotion_output\": \"accuracy\",\n",
    "        \"confidence_output\": \"mse\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a611b4-17ce-4629-91a0-45b4c6fcc961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\3879632540.py\", line 1, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 6 4 1 4 5 6 7 6 3 5 6 0 6 1 7 5 1 2 3 3 2 2 4 1 5 1 5 2 2 7 7 7\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_17794]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_val\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\3879632540.py\", line 1, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 6 4 1 4 5 6 7 6 3 5 6 0 6 1 7 5 1 2 3 3 2 2 4 1 5 1 5 2 2 7 7 7\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_17794]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\"emotion_output\": y_train, \"confidence_output\": conf_train},\n",
    "    validation_data=(X_val, {\"emotion_output\": y_val, \"confidence_output\": conf_val}),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca542689-2ef8-4fe8-81f0-965636db7efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training data: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in validation data: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in test data: [0 1 2 3 4 5 6 7]\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\1381722360.py\", line 35, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 7 3 1 2 0 4 4 1 5 3 3 7 4 3 1 4 4 6 4 4 1 5 1 5 1 5 4 6 5 2 6 4\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_23651]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique labels in test data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39munique(y_test))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_val\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     42\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\1381722360.py\", line 35, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 7 3 1 2 0 4 4 1 5 3 3 7 4 3 1 4 4 6 4 4 1 5 1 5 1 5 4 6 5 2 6 4\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_23651]"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "input_layer = tf.keras.layers.Input(shape=(59, 1), name=\"input_layer\")\n",
    "x = tf.keras.layers.Masking(mask_value=0)(input_layer)\n",
    "x = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=1)(x, x)\n",
    "x = tf.keras.layers.LayerNormalization()(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "lstm_output = tf.keras.layers.LSTM(128)(x)\n",
    "\n",
    "# Output layers\n",
    "emotion_output = tf.keras.layers.Dense(8, activation=\"softmax\", name=\"emotion_output\")(lstm_output)\n",
    "confidence_output = tf.keras.layers.Dense(1, activation=\"linear\", name=\"confidence_output\")(lstm_output)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=[emotion_output, confidence_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"emotion_output\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        \"confidence_output\": tf.keras.losses.MeanSquaredError()\n",
    "    },\n",
    "    metrics={\n",
    "        \"emotion_output\": \"accuracy\",\n",
    "        \"confidence_output\": \"mse\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Verify the labels\n",
    "print(\"Unique labels in training data:\", np.unique(y_train))\n",
    "print(\"Unique labels in validation data:\", np.unique(y_val))\n",
    "print(\"Unique labels in test data:\", np.unique(y_test))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\"emotion_output\": y_train, \"confidence_output\": conf_train},\n",
    "    validation_data=(X_val, {\"emotion_output\": y_val, \"confidence_output\": conf_val}),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a5df6e4-51ea-4a8c-9109-195e99f4caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(y_train >= 0) and np.all(y_train < 8)\n",
    "assert np.all(y_val >= 0) and np.all(y_val < 8)\n",
    "assert np.all(y_test >= 0) and np.all(y_test < 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79337168-47f6-4bc2-bcd4-3a57e45be686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step\n",
      "Emotion output shape: (5, 8)\n",
      "Confidence output shape: (5, 1)\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_train[:5])\n",
    "print(\"Emotion output shape:\", preds[0].shape)\n",
    "print(\"Confidence output shape:\", preds[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "523dc104-8d5a-478a-96e1-cb5f9ce85be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample emotion labels (y_train): [5 3 2 5 6 2 5 5 4 7]\n",
      "Sample confidence labels (conf_train): [[0.75]\n",
      " [0.7 ]\n",
      " [0.85]\n",
      " [0.75]\n",
      " [0.88]\n",
      " [0.85]\n",
      " [0.75]\n",
      " [0.75]\n",
      " [0.95]\n",
      " [0.92]]\n",
      "Unique emotion labels: [0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample emotion labels (y_train):\", y_train[:10])\n",
    "print(\"Sample confidence labels (conf_train):\", conf_train[:10])\n",
    "print(\"Unique emotion labels:\", np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2310be2-5627-4032-bee1-54be9e0d5655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"emotion_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"confidence_output\": \"mean_squared_error\"\n",
    "    },\n",
    "    metrics={\n",
    "        \"emotion_output\": \"accuracy\",\n",
    "        \"confidence_output\": \"mse\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f867f197-5bfa-45df-a696-10399fcdcfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\3879632540.py\", line 1, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 0 2 6 6 7 4 4 3 3 2 3 3 4 5 5 5 1 2 1 3 4 5 3 7 4 7 6 3 6 7 4 7\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_29708]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_val\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\3879632540.py\", line 1, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 0 2 6 6 7 4 4 3 3 2 3 3 4 5 5 5 1 2 1 3 4 5 3 7 4 7 6 3 6 7 4 7\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_29708]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\"emotion_output\": y_train, \"confidence_output\": conf_train},\n",
    "    validation_data=(X_val, {\"emotion_output\": y_val, \"confidence_output\": conf_val}),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc130f0b-100c-4921-8305-8d06b5d131fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training data: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in validation data: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in test data: [0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in training data:\", np.unique(y_train))\n",
    "print(\"Unique labels in validation data:\", np.unique(y_val))\n",
    "print(\"Unique labels in test data:\", np.unique(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3001d4d3-80eb-47d8-95bc-950c67677373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"emotion_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"confidence_output\": \"mean_squared_error\"\n",
    "    },\n",
    "    metrics={\n",
    "        \"emotion_output\": \"accuracy\",\n",
    "        \"confidence_output\": \"mse\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49a94bd8-a3ba-4959-9960-6cc8716cf63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train: (1008,)\n",
      "Shape of y_val: (216,)\n",
      "Shape of y_test: (216,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9333dade-594d-48c6-9d9a-b09218c16013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in y_train: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in y_val: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in y_test: [0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in y_train:\", np.unique(y_train))\n",
    "print(\"Unique labels in y_val:\", np.unique(y_val))\n",
    "print(\"Unique labels in y_test:\", np.unique(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de7955d8-9403-4594-9bf9-0e8d50e383b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"emotion_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"confidence_output\": \"mean_squared_error\"\n",
    "    },\n",
    "    metrics={\n",
    "        \"emotion_output\": \"accuracy\",\n",
    "        \"confidence_output\": \"mse\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e75f292-8a26-4ee0-ba33-2be9b7d41cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step\n",
      "Emotion output shape: (5, 8)\n",
      "Confidence output shape: (5, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_output = model.predict(X_train[:5])\n",
    "print(\"Emotion output shape:\", sample_output[0].shape)  # Expected: (5, 8)\n",
    "print(\"Confidence output shape:\", sample_output[1].shape)  # Expected: (5, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed5af3da-b240-489b-bdb7-884988b224f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.clip(y_train, 0, 7).astype(int)\n",
    "y_val = np.clip(y_val, 0, 7).astype(int)\n",
    "y_test = np.clip(y_test, 0, 7).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2523d400-011a-4ad3-b905-fc1b597c31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis=-1) if y_train.ndim > 1 else y_train\n",
    "y_val = np.argmax(y_val, axis=-1) if y_val.ndim > 1 else y_val\n",
    "y_test = np.argmax(y_test, axis=-1) if y_test.ndim > 1 else y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ced0c4b8-1244-4f94-84ad-9091a3f1c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\3879632540.py\", line 1, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 7 4 5 5 1 1 2 0 1 2 1 1 1 3 3 0 2 5 4 0 6 1 3 4 7 0 6 7 2 7 4 1\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_35710]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_val\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\3879632540.py\", line 1, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 7 4 5 5 1 1 2 0 1 2 1 1 1 3 3 0 2 5 4 0 6 1 3 4 7 0 6 7 2 7 4 1\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_35710]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\"emotion_output\": y_train, \"confidence_output\": conf_train},\n",
    "    validation_data=(X_val, {\"emotion_output\": y_val, \"confidence_output\": conf_val}),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38d55907-d060-4516-9cf8-97708171b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in y_train: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in y_val: [0 1 2 3 4 5 6 7]\n",
      "Unique labels in y_test: [0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Unique labels in y_train:\", np.unique(y_train))\n",
    "print(\"Unique labels in y_val:\", np.unique(y_val))\n",
    "print(\"Unique labels in y_test:\", np.unique(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b398c7-5838-4a4c-9f61-8bce967d0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.clip(y_train, 0, 7).astype(int)\n",
    "y_val = np.clip(y_val, 0, 7).astype(int)\n",
    "y_test = np.clip(y_test, 0, 7).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59751366-03d9-4d92-9ab4-487b9912d364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │ masking_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ masking_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ any_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ multi_head_attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_3 (\u001b[38;5;33mNotEqual\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_3 (\u001b[38;5;33mMasking\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_3 (\u001b[38;5;33mAny\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │              \u001b[38;5;34m15\u001b[0m │ masking_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ masking_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ any_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m2\u001b[0m │ multi_head_attention_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │           \u001b[38;5;34m1,032\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">300,368</span> (1.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m300,368\u001b[0m (1.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,122</span> (391.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,122\u001b[0m (391.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,246</span> (782.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m200,246\u001b[0m (782.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e360c06-6354-496c-bb72-bf89b1e1e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.clip(y_train, 0, 7).astype(int)\n",
    "y_val = np.clip(y_val, 0, 7).astype(int)\n",
    "y_test = np.clip(y_test, 0, 7).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03218dcb-720c-42ed-8558-3c51026f086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1008, 59, 1)\n",
      "Shape of y_train: (1008,)\n",
      "Shape of conf_train: (1008, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of conf_train:\", conf_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9abc02a5-68b9-480b-a4fe-7f468549b2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Emotion output shape: (5, 8)\n",
      "Confidence output shape: (5, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_output = model.predict(X_train[:5])\n",
    "print(\"Emotion output shape:\", sample_output[0].shape)  # Expect (5, 8)\n",
    "print(\"Confidence output shape:\", sample_output[1].shape)  # Expect (5, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe707b63-9b95-44d4-96fb-05074770344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"emotion_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"confidence_output\": \"mean_squared_error\"\n",
    "    },\n",
    "    metrics={\n",
    "        \"emotion_output\": \"accuracy\",\n",
    "        \"confidence_output\": \"mse\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "465c4e73-bd7d-4432-a5ab-dc5c21da2f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\3879632540.py\", line 1, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 1 3 3 5 4 3 2 4 6 4 2 3 1 0 2 7 6 4 4 3 2 5 5 5 6 3 5 1 4 2 0 2\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_41403]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_val\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14424\\3879632540.py\", line 1, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 1 3 3 5 4 3 2 4 6 4 2 3 1 0 2 7 6 4 4 3 2 5 5 5 6 3 5 1 4 2 0 2\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_41403]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\"emotion_output\": y_train, \"confidence_output\": conf_train},\n",
    "    validation_data=(X_val, {\"emotion_output\": y_val, \"confidence_output\": conf_val}),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57109f19-ebdd-4e02-8f68-9fa49b1c625d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path to dataset\n",
    "DATA_PATH = \"C:/Users/admin/Desktop/Voice Expression Detection Model1/\"\n",
    "\n",
    "# Preprocess audio files\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    return np.hstack([mfccs.mean(axis=1), chroma.mean(axis=1), spectral_contrast.mean(axis=1)])\n",
    "\n",
    "# Parse metadata from filenames\n",
    "def parse_emotion_from_filename(filename):\n",
    "    # Assuming RAVDESS naming conventions\n",
    "    parts = filename.split('-')\n",
    "    emotion_code = parts[2]  # Extract emotion code\n",
    "    return int(emotion_code)\n",
    "\n",
    "# Process all files\n",
    "data = []\n",
    "for actor_folder in os.listdir(DATA_PATH):\n",
    "    folder_path = os.path.join(DATA_PATH, actor_folder)\n",
    "    if os.path.isdir(folder_path):  # Ensure it's a folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):  # Process only .wav files\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                features = extract_features(file_path)\n",
    "                label = parse_emotion_from_filename(file)  # Extract emotion label\n",
    "                data.append((features, label))\n",
    "\n",
    "# Create DataFrame\n",
    "features_df = pd.DataFrame(data, columns=[\"features\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea0f267-32a7-42bc-b069-ba1e08afe2b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Normalize features\u001b[39;00m\n\u001b[0;32m      9\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m---> 10\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Split the data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m X_train, X_temp, y_train, y_temp \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m             )\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert features and labels into arrays\n",
    "X = np.array(features_df[\"features\"].tolist())\n",
    "y = np.array(features_df[\"label\"].tolist())\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reshape for LSTM (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8383fa-41c4-4837-81f0-8e6335f3d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [features, label]\n",
      "Index: []\n",
      "(0, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature extraction failed. Check your dataset and preprocessing.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(features_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Handle empty features\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature extraction failed. Check your dataset and preprocessing.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Ensure X is 2D\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Feature extraction failed. Check your dataset and preprocessing."
     ]
    }
   ],
   "source": [
    "# Check features_df\n",
    "print(features_df.head())\n",
    "print(features_df.shape)\n",
    "\n",
    "# Convert features to array\n",
    "X = np.array(features_df[\"features\"].tolist())\n",
    "if X.size == 0:  # Handle empty features\n",
    "    raise ValueError(\"Feature extraction failed. Check your dataset and preprocessing.\")\n",
    "\n",
    "# Ensure X is 2D\n",
    "if len(X.shape) == 1:\n",
    "    X = np.expand_dims(X, axis=1)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Proceed with train-test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reshape for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c387d1e-41c4-4f77-9a5f-870fb52f197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolders in DATA_PATH:\n",
      "['Dataset_Link.txt', 'Giggle_Function_2']\n",
      "Files in Giggle_Function_2:\n",
      "['.git', '.ipynb_checkpoints', 'Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05', 'Actor_06', 'Actor_07', 'Actor_08', 'Actor_09', 'Actor_10', 'Actor_11', 'Actor_12', 'Actor_13', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_20', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_24', 'archive (11).zip', 'audio_speech_actors_01-24', 'Untitled.ipynb', 'Untitled1.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATA_PATH = \"C:/Users/admin/Desktop/Voice Expression Detection Model1/\"\n",
    "print(\"Subfolders in DATA_PATH:\")\n",
    "print(os.listdir(DATA_PATH))  # List subfolders in the dataset directory\n",
    "\n",
    "for folder in os.listdir(DATA_PATH):\n",
    "    folder_path = os.path.join(DATA_PATH, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"Files in {folder}:\")\n",
    "        print(os.listdir(folder_path))  # List files in each subfolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f94c12f9-1ab6-49e1-98fb-8b5980c8820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-01-01-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-01-01-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-01-01-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-01-01-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-02-01-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-02-01-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-02-01-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-02-01-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-02-02-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-02-02-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-02-02-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-02-02-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-03-01-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-03-01-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-03-01-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-03-01-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-03-02-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-03-02-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-03-02-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-03-02-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-04-01-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-04-01-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-04-01-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-04-01-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-04-02-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-04-02-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-04-02-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-04-02-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-05-01-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-05-01-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-05-01-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-05-01-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-05-02-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-05-02-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-05-02-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-05-02-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-06-01-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-06-01-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-06-01-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-06-01-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-06-02-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-06-02-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-06-02-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-06-02-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-07-01-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-07-01-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-07-01-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-07-01-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-07-02-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-07-02-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-07-02-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-07-02-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-08-01-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-08-01-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-08-01-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-08-01-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-08-02-01-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-08-02-01-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-08-02-02-01-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_01\\03-01-08-02-02-02-01.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-01-01-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-01-01-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-01-01-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-01-01-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-02-01-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-02-01-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-02-01-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-02-01-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-02-02-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-02-02-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-02-02-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-02-02-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-03-01-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-03-01-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-03-01-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-03-01-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-03-02-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-03-02-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-03-02-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-03-02-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-04-01-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-04-01-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-04-01-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-04-01-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-04-02-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-04-02-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-04-02-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-04-02-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-05-01-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-05-01-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-05-01-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-05-01-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-05-02-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-05-02-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-05-02-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-05-02-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-06-01-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-06-01-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-06-01-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-06-01-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-06-02-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-06-02-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-06-02-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-06-02-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-07-01-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-07-01-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-07-01-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-07-01-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-07-02-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-07-02-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-07-02-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-07-02-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-08-01-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-08-01-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-08-01-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-08-01-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-08-02-01-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-08-02-01-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-08-02-02-01-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_02\\03-01-08-02-02-02-02.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-01-01-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-01-01-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-01-01-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-01-01-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-02-01-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-02-01-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-02-01-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-02-01-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-02-02-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-02-02-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-02-02-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-02-02-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-03-01-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-03-01-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-03-01-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-03-01-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-03-02-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-03-02-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-03-02-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-03-02-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-04-01-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-04-01-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-04-01-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-04-01-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-04-02-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-04-02-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-04-02-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-04-02-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-05-01-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-05-01-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-05-01-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-05-01-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-05-02-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-05-02-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-05-02-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-05-02-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-06-01-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-06-01-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-06-01-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-06-01-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-06-02-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-06-02-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-06-02-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-06-02-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-07-01-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-07-01-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-07-01-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-07-01-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-07-02-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-07-02-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-07-02-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-07-02-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-08-01-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-08-01-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-08-01-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-08-01-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-08-02-01-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-08-02-01-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-08-02-02-01-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_03\\03-01-08-02-02-02-03.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-01-01-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-01-01-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-01-01-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-01-01-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-02-01-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-02-01-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-02-01-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-02-01-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-02-02-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-02-02-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-02-02-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-02-02-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-03-01-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-03-01-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-03-01-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-03-01-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-03-02-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-03-02-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-03-02-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-03-02-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-04-01-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-04-01-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-04-01-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-04-01-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-04-02-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-04-02-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-04-02-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-04-02-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-05-01-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-05-01-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-05-01-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-05-01-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-05-02-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-05-02-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-05-02-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-05-02-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-06-01-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-06-01-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-06-01-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-06-01-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-06-02-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-06-02-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-06-02-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-06-02-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-07-01-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-07-01-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-07-01-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-07-01-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-07-02-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-07-02-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-07-02-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-07-02-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-08-01-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-08-01-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-08-01-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-08-01-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-08-02-01-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-08-02-01-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-08-02-02-01-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_04\\03-01-08-02-02-02-04.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-01-01-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-01-01-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-01-01-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-01-01-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-02-01-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-02-01-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-02-01-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-02-01-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-02-02-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-02-02-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-02-02-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-02-02-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-03-01-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-03-01-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-03-01-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-03-01-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-03-02-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-03-02-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-03-02-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-03-02-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-04-01-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-04-01-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-04-01-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-04-01-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-04-02-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-04-02-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-04-02-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-04-02-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-05-01-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-05-01-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-05-01-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-05-01-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-05-02-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-05-02-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-05-02-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-05-02-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-06-01-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-06-01-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-06-01-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-06-01-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-06-02-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-06-02-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-06-02-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-06-02-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-07-01-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-07-01-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-07-01-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-07-01-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-07-02-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-07-02-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-07-02-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-07-02-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-08-01-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-08-01-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-08-01-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-08-01-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-08-02-01-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-08-02-01-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-08-02-02-01-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_05\\03-01-08-02-02-02-05.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-01-01-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-01-01-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-01-01-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-01-01-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-02-01-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-02-01-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-02-01-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-02-01-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-02-02-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-02-02-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-02-02-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-02-02-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-03-01-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-03-01-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-03-01-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-03-01-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-03-02-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-03-02-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-03-02-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-03-02-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-04-01-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-04-01-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-04-01-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-04-01-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-04-02-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-04-02-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-04-02-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-04-02-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-05-01-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-05-01-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-05-01-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-05-01-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-05-02-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-05-02-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-05-02-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-05-02-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-06-01-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-06-01-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-06-01-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-06-01-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-06-02-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-06-02-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-06-02-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-06-02-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-07-01-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-07-01-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-07-01-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-07-01-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-07-02-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-07-02-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-07-02-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-07-02-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-08-01-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-08-01-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-08-01-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-08-01-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-08-02-01-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-08-02-01-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-08-02-02-01-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_06\\03-01-08-02-02-02-06.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-01-01-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-01-01-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-01-01-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-01-01-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-02-01-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-02-01-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-02-01-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-02-01-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-02-02-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-02-02-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-02-02-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-02-02-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-03-01-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-03-01-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-03-01-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-03-01-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-03-02-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-03-02-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-03-02-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-03-02-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-04-01-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-04-01-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-04-01-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-04-01-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-04-02-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-04-02-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-04-02-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-04-02-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-05-01-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-05-01-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-05-01-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-05-01-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-05-02-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-05-02-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-05-02-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-05-02-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-06-01-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-06-01-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-06-01-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-06-01-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-06-02-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-06-02-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-06-02-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-06-02-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-07-01-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-07-01-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-07-01-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-07-01-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-07-02-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-07-02-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-07-02-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-07-02-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-08-01-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-08-01-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-08-01-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-08-01-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-08-02-01-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-08-02-01-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-08-02-02-01-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_07\\03-01-08-02-02-02-07.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-01-01-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-01-01-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-01-01-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-01-01-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-02-01-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-02-01-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-02-01-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-02-01-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-02-02-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-02-02-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-02-02-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-02-02-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-03-01-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-03-01-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-03-01-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-03-01-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-03-02-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-03-02-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-03-02-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-03-02-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-04-01-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-04-01-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-04-01-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-04-01-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-04-02-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-04-02-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-04-02-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-04-02-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-05-01-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-05-01-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-05-01-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-05-01-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-05-02-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-05-02-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-05-02-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-05-02-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-06-01-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-06-01-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-06-01-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-06-01-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-06-02-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-06-02-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-06-02-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-06-02-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-07-01-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-07-01-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-07-01-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-07-01-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-07-02-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-07-02-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-07-02-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-07-02-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-08-01-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-08-01-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-08-01-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-08-01-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-08-02-01-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-08-02-01-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-08-02-02-01-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_08\\03-01-08-02-02-02-08.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-01-01-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-01-01-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-01-01-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-01-01-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-02-01-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-02-01-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-02-01-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-02-01-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-02-02-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-02-02-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-02-02-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-02-02-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-03-01-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-03-01-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-03-01-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-03-01-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-03-02-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-03-02-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-03-02-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-03-02-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-04-01-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-04-01-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-04-01-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-04-01-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-04-02-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-04-02-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-04-02-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-04-02-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-05-01-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-05-01-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-05-01-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-05-01-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-05-02-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-05-02-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-05-02-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-05-02-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-06-01-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-06-01-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-06-01-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-06-01-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-06-02-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-06-02-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-06-02-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-06-02-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-07-01-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-07-01-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-07-01-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-07-01-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-07-02-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-07-02-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-07-02-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-07-02-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-08-01-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-08-01-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-08-01-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-08-01-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-08-02-01-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-08-02-01-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-08-02-02-01-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_09\\03-01-08-02-02-02-09.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-01-01-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-01-01-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-01-01-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-01-01-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-02-01-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-02-01-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-02-01-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-02-01-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-02-02-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-02-02-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-02-02-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-02-02-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-03-01-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-03-01-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-03-01-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-03-01-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-03-02-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-03-02-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-03-02-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-03-02-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-04-01-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-04-01-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-04-01-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-04-01-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-04-02-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-04-02-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-04-02-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-04-02-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-05-01-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-05-01-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-05-01-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-05-01-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-05-02-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-05-02-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-05-02-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-05-02-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-06-01-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-06-01-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-06-01-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-06-01-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-06-02-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-06-02-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-06-02-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-06-02-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-07-01-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-07-01-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-07-01-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-07-01-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-07-02-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-07-02-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-07-02-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-07-02-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-08-01-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-08-01-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-08-01-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-08-01-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-08-02-01-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-08-02-01-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-08-02-02-01-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_10\\03-01-08-02-02-02-10.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-01-01-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-01-01-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-01-01-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-01-01-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-02-01-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-02-01-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-02-01-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-02-01-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-02-02-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-02-02-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-02-02-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-02-02-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-03-01-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-03-01-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-03-01-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-03-01-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-03-02-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-03-02-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-03-02-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-03-02-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-04-01-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-04-01-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-04-01-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-04-01-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-04-02-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-04-02-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-04-02-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-04-02-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-05-01-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-05-01-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-05-01-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-05-01-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-05-02-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-05-02-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-05-02-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-05-02-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-06-01-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-06-01-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-06-01-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-06-01-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-06-02-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-06-02-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-06-02-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-06-02-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-07-01-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-07-01-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-07-01-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-07-01-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-07-02-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-07-02-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-07-02-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-07-02-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-08-01-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-08-01-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-08-01-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-08-01-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-08-02-01-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-08-02-01-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-08-02-02-01-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_11\\03-01-08-02-02-02-11.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-01-01-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-01-01-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-01-01-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-01-01-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-02-01-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-02-01-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-02-01-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-02-01-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-02-02-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-02-02-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-02-02-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-02-02-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-03-01-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-03-01-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-03-01-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-03-01-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-03-02-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-03-02-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-03-02-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-03-02-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-04-01-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-04-01-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-04-01-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-04-01-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-04-02-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-04-02-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-04-02-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-04-02-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-05-01-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-05-01-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-05-01-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-05-01-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-05-02-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-05-02-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-05-02-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-05-02-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-06-01-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-06-01-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-06-01-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-06-01-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-06-02-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-06-02-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-06-02-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-06-02-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-07-01-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-07-01-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-07-01-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-07-01-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-07-02-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-07-02-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-07-02-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-07-02-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-08-01-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-08-01-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-08-01-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-08-01-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-08-02-01-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-08-02-01-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-08-02-02-01-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_12\\03-01-08-02-02-02-12.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-01-01-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-01-01-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-01-01-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-01-01-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-02-01-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-02-01-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-02-01-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-02-01-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-02-02-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-02-02-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-02-02-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-02-02-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-03-01-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-03-01-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-03-01-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-03-01-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-03-02-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-03-02-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-03-02-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-03-02-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-04-01-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-04-01-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-04-01-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-04-01-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-04-02-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-04-02-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-04-02-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-04-02-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-05-01-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-05-01-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-05-01-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-05-01-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-05-02-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-05-02-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-05-02-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-05-02-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-06-01-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-06-01-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-06-01-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-06-01-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-06-02-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-06-02-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-06-02-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-06-02-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-07-01-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-07-01-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-07-01-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-07-01-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-07-02-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-07-02-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-07-02-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-07-02-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-08-01-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-08-01-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-08-01-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-08-01-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-08-02-01-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-08-02-01-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-08-02-02-01-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_13\\03-01-08-02-02-02-13.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-01-01-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-01-01-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-01-01-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-01-01-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-02-01-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-02-01-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-02-01-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-02-01-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-02-02-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-02-02-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-02-02-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-02-02-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-03-01-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-03-01-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-03-01-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-03-01-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-03-02-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-03-02-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-03-02-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-03-02-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-04-01-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-04-01-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-04-01-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-04-01-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-04-02-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-04-02-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-04-02-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-04-02-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-05-01-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-05-01-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-05-01-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-05-01-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-05-02-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-05-02-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-05-02-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-05-02-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-06-01-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-06-01-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-06-01-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-06-01-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-06-02-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-06-02-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-06-02-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-06-02-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-07-01-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-07-01-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-07-01-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-07-01-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-07-02-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-07-02-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-07-02-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-07-02-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-08-01-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-08-01-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-08-01-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-08-01-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-08-02-01-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-08-02-01-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-08-02-02-01-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_14\\03-01-08-02-02-02-14.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-01-01-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-01-01-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-01-01-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-01-01-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-02-01-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-02-01-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-02-01-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-02-01-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-02-02-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-02-02-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-02-02-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-02-02-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-03-01-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-03-01-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-03-01-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-03-01-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-03-02-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-03-02-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-03-02-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-03-02-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-04-01-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-04-01-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-04-01-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-04-01-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-04-02-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-04-02-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-04-02-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-04-02-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-05-01-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-05-01-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-05-01-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-05-01-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-05-02-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-05-02-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-05-02-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-05-02-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-06-01-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-06-01-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-06-01-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-06-01-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-06-02-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-06-02-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-06-02-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-06-02-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-07-01-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-07-01-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-07-01-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-07-01-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-07-02-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-07-02-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-07-02-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-07-02-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-08-01-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-08-01-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-08-01-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-08-01-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-08-02-01-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-08-02-01-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-08-02-02-01-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_15\\03-01-08-02-02-02-15.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-01-01-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-01-01-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-01-01-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-01-01-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-02-01-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-02-01-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-02-01-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-02-01-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-02-02-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-02-02-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-02-02-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-02-02-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-03-01-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-03-01-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-03-01-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-03-01-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-03-02-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-03-02-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-03-02-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-03-02-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-04-01-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-04-01-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-04-01-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-04-01-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-04-02-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-04-02-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-04-02-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-04-02-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-05-01-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-05-01-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-05-01-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-05-01-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-05-02-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-05-02-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-05-02-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-05-02-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-06-01-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-06-01-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-06-01-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-06-01-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-06-02-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-06-02-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-06-02-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-06-02-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-07-01-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-07-01-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-07-01-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-07-01-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-07-02-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-07-02-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-07-02-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-07-02-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-08-01-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-08-01-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-08-01-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-08-01-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-08-02-01-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-08-02-01-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-08-02-02-01-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_16\\03-01-08-02-02-02-16.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-01-01-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-01-01-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-01-01-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-01-01-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-02-01-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-02-01-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-02-01-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-02-01-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-02-02-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-02-02-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-02-02-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-02-02-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-03-01-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-03-01-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-03-01-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-03-01-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-03-02-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-03-02-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-03-02-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-03-02-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-04-01-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-04-01-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-04-01-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-04-01-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-04-02-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-04-02-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-04-02-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-04-02-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-05-01-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-05-01-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-05-01-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-05-01-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-05-02-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-05-02-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-05-02-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-05-02-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-06-01-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-06-01-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-06-01-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-06-01-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-06-02-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-06-02-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-06-02-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-06-02-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-07-01-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-07-01-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-07-01-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-07-01-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-07-02-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-07-02-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-07-02-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-07-02-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-08-01-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-08-01-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-08-01-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-08-01-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-08-02-01-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-08-02-01-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-08-02-02-01-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_17\\03-01-08-02-02-02-17.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-01-01-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-01-01-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-01-01-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-01-01-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-02-01-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-02-01-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-02-01-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-02-01-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-02-02-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-02-02-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-02-02-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-02-02-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-03-01-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-03-01-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-03-01-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-03-01-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-03-02-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-03-02-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-03-02-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-03-02-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-04-01-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-04-01-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-04-01-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-04-01-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-04-02-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-04-02-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-04-02-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-04-02-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-05-01-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-05-01-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-05-01-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-05-01-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-05-02-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-05-02-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-05-02-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-05-02-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-06-01-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-06-01-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-06-01-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-06-01-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-06-02-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-06-02-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-06-02-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-06-02-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-07-01-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-07-01-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-07-01-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-07-01-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-07-02-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-07-02-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-07-02-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-07-02-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-08-01-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-08-01-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-08-01-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-08-01-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-08-02-01-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-08-02-01-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-08-02-02-01-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_18\\03-01-08-02-02-02-18.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-01-01-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-01-01-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-01-01-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-01-01-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-02-01-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-02-01-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-02-01-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-02-01-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-02-02-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-02-02-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-02-02-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-02-02-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-03-01-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-03-01-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-03-01-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-03-01-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-03-02-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-03-02-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-03-02-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-03-02-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-04-01-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-04-01-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-04-01-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-04-01-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-04-02-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-04-02-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-04-02-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-04-02-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-05-01-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-05-01-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-05-01-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-05-01-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-05-02-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-05-02-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-05-02-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-05-02-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-06-01-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-06-01-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-06-01-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-06-01-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-06-02-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-06-02-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-06-02-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-06-02-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-07-01-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-07-01-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-07-01-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-07-01-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-07-02-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-07-02-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-07-02-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-07-02-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-08-01-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-08-01-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-08-01-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-08-01-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-08-02-01-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-08-02-01-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-08-02-02-01-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_19\\03-01-08-02-02-02-19.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-01-01-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-01-01-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-01-01-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-01-01-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-02-01-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-02-01-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-02-01-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-02-01-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-02-02-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-02-02-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-02-02-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-02-02-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-03-01-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-03-01-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-03-01-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-03-01-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-03-02-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-03-02-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-03-02-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-03-02-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-04-01-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-04-01-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-04-01-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-04-01-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-04-02-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-04-02-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-04-02-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-04-02-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-05-01-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-05-01-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-05-01-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-05-01-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-05-02-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-05-02-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-05-02-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-05-02-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-06-01-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-06-01-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-06-01-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-06-01-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-06-02-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-06-02-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-06-02-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-06-02-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-07-01-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-07-01-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-07-01-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-07-01-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-07-02-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-07-02-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-07-02-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-07-02-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-08-01-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-08-01-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-08-01-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-08-01-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-08-02-01-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-08-02-01-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-08-02-02-01-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_20\\03-01-08-02-02-02-20.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-01-01-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-01-01-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-01-01-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-01-01-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-02-01-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-02-01-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-02-01-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-02-01-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-02-02-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-02-02-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-02-02-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-02-02-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-03-01-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-03-01-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-03-01-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-03-01-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-03-02-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-03-02-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-03-02-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-03-02-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-04-01-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-04-01-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-04-01-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-04-01-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-04-02-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-04-02-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-04-02-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-04-02-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-05-01-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-05-01-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-05-01-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-05-01-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-05-02-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-05-02-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-05-02-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-05-02-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-06-01-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-06-01-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-06-01-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-06-01-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-06-02-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-06-02-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-06-02-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-06-02-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-07-01-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-07-01-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-07-01-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-07-01-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-07-02-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-07-02-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-07-02-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-07-02-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-08-01-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-08-01-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-08-01-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-08-01-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-08-02-01-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-08-02-01-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-08-02-02-01-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_21\\03-01-08-02-02-02-21.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-01-01-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-01-01-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-01-01-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-01-01-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-02-01-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-02-01-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-02-01-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-02-01-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-02-02-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-02-02-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-02-02-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-02-02-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-03-01-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-03-01-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-03-01-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-03-01-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-03-02-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-03-02-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-03-02-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-03-02-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-04-01-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-04-01-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-04-01-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-04-01-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-04-02-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-04-02-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-04-02-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-04-02-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-05-01-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-05-01-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-05-01-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-05-01-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-05-02-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-05-02-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-05-02-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-05-02-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-06-01-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-06-01-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-06-01-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-06-01-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-06-02-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-06-02-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-06-02-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-06-02-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-07-01-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-07-01-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-07-01-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-07-01-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-07-02-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-07-02-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-07-02-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-07-02-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-08-01-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-08-01-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-08-01-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-08-01-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-08-02-01-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-08-02-01-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-08-02-02-01-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_22\\03-01-08-02-02-02-22.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-01-01-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-01-01-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-01-01-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-01-01-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-02-01-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-02-01-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-02-01-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-02-01-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-02-02-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-02-02-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-02-02-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-02-02-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-03-01-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-03-01-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-03-01-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-03-01-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-03-02-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-03-02-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-03-02-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-03-02-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-04-01-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-04-01-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-04-01-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-04-01-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-04-02-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-04-02-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-04-02-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-04-02-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-05-01-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-05-01-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-05-01-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-05-01-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-05-02-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-05-02-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-05-02-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-05-02-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-06-01-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-06-01-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-06-01-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-06-01-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-06-02-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-06-02-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-06-02-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-06-02-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-07-01-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-07-01-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-07-01-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-07-01-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-07-02-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-07-02-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-07-02-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-07-02-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-08-01-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-08-01-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-08-01-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-08-01-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-08-02-01-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-08-02-01-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-08-02-02-01-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_23\\03-01-08-02-02-02-23.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-01-01-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-01-01-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-01-01-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-01-01-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-02-01-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-02-01-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-02-01-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-02-01-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-02-02-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-02-02-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-02-02-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-02-02-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-03-01-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-03-01-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-03-01-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-03-01-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-03-02-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-03-02-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-03-02-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-03-02-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-04-01-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-04-01-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-04-01-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-04-01-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-04-02-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-04-02-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-04-02-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-04-02-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-05-01-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-05-01-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-05-01-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-05-01-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-05-02-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-05-02-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-05-02-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-05-02-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-06-01-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-06-01-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-06-01-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-06-01-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-06-02-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-06-02-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-06-02-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-06-02-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-07-01-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-07-01-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-07-01-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-07-01-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-07-02-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-07-02-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-07-02-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-07-02-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-08-01-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-08-01-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-08-01-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-08-01-02-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-08-02-01-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-08-02-01-02-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-08-02-02-01-24.wav\n",
      "Processing C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/Actor_24\\03-01-08-02-02-02-24.wav\n",
      "                                            features  label\n",
      "0  [-694.2315063476562, 50.04055404663086, 0.5522...      1\n",
      "1  [-683.9196166992188, 49.147438049316406, -1.77...      1\n",
      "2  [-678.0790405273438, 51.5277099609375, -0.0380...      1\n",
      "3  [-674.4396362304688, 50.82819747924805, 1.7249...      1\n",
      "4  [-709.8828125, 56.2994384765625, 2.66253113746...      2\n",
      "(1440, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Update DATA_PATH to point to the correct folder\n",
    "DATA_PATH = \"C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/\"\n",
    "\n",
    "# Preprocess audio files\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=16000)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        return np.hstack([mfccs.mean(axis=1), chroma.mean(axis=1), spectral_contrast.mean(axis=1)])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Parse metadata from filenames\n",
    "def parse_emotion_from_filename(filename):\n",
    "    parts = filename.split('-')\n",
    "    return int(parts[2])  # Assuming RAVDESS naming conventions\n",
    "\n",
    "# Process all actor folders\n",
    "data = []\n",
    "for actor_folder in os.listdir(DATA_PATH):\n",
    "    folder_path = os.path.join(DATA_PATH, actor_folder)\n",
    "    if os.path.isdir(folder_path):  # Ensure it's a folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):  # Process only .wav files\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                print(f\"Processing {file_path}\")\n",
    "                features = extract_features(file_path)\n",
    "                if features is not None:  # Only include valid features\n",
    "                    label = parse_emotion_from_filename(file)\n",
    "                    data.append((features, label))\n",
    "\n",
    "# Create a DataFrame\n",
    "features_df = pd.DataFrame(data, columns=[\"features\", \"label\"])\n",
    "\n",
    "# Verify the DataFrame\n",
    "print(features_df.head())\n",
    "print(features_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e17fd87e-14b8-4927-9faf-4bf0f14c6a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1008, 59, 1), (1008,)\n",
      "Validation data shape: (216, 59, 1), (216,)\n",
      "Test data shape: (216, 59, 1), (216,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert features and labels into arrays\n",
    "X = np.array(features_df[\"features\"].tolist())\n",
    "y = np.array(features_df[\"label\"].tolist())\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reshape for LSTM (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f7b6fa-ccdf-48ed-9769-edbebc0b60b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">897</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                               │                           │                 │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any (\u001b[38;5;33mAny\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m897\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                               │                           │                 │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m2\u001b[0m │ multi_head_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │           \u001b[38;5;34m1,032\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,875</span> (394.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,875\u001b[0m (394.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,875</span> (394.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,875\u001b[0m (394.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the Transformer-LSTM Model\n",
    "def build_transformer_lstm(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Masking()(inputs)\n",
    "\n",
    "    # Transformer Encoder\n",
    "    x = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "    # LSTM\n",
    "    x = layers.LSTM(128, return_sequences=False)(x)\n",
    "\n",
    "    # Output layer for emotion classification\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "num_classes = len(np.unique(y))  # Number of unique emotion labels\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "model = build_transformer_lstm(input_shape, num_classes)\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bac0623-b83e-4cac-a0e8-e8798b53fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4760\\3072454354.py\", line 2, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 8 which is outside the valid range of [0, 8).  Label values: 8 2 5 8 6 6 1 1 4 1 6 7 8 6 5 6 2 3 8 3 5 4 4 2 4 8 2 5 6 2 4 5\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_5112]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4760\\3072454354.py\", line 2, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 8 which is outside the valid range of [0, 8).  Label values: 8 2 5 8 6 6 1 1 4 1 6 7 8 6 5 6 2 3 8 3 5 4 4 2 4 8 2 5 6 2 4 5\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_5112]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdafd312-737b-473b-a058-10935afac050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">897</span> │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ multi_head_attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_1 (\u001b[38;5;33mAny\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m897\u001b[0m │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m2\u001b[0m │ multi_head_attention_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │           \u001b[38;5;34m1,032\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,875</span> (394.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,875\u001b[0m (394.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,875</span> (394.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,875\u001b[0m (394.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - accuracy: 0.1207 - loss: 2.0778 - val_accuracy: 0.1157 - val_loss: 2.0533\n",
      "Epoch 2/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1464 - loss: 2.0643 - val_accuracy: 0.1157 - val_loss: 2.0603\n",
      "Epoch 3/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1464 - loss: 2.0648 - val_accuracy: 0.1157 - val_loss: 2.0526\n",
      "Epoch 4/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.1453 - loss: 2.0646 - val_accuracy: 0.1157 - val_loss: 2.0514\n",
      "Epoch 5/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.1372 - loss: 2.0586 - val_accuracy: 0.1157 - val_loss: 2.0554\n",
      "Epoch 6/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1581 - loss: 2.0639 - val_accuracy: 0.1157 - val_loss: 2.0516\n",
      "Epoch 7/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.1613 - loss: 2.0616 - val_accuracy: 0.1157 - val_loss: 2.0548\n",
      "Epoch 8/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.1329 - loss: 2.0640 - val_accuracy: 0.1157 - val_loss: 2.0509\n",
      "Epoch 9/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1527 - loss: 2.0619 - val_accuracy: 0.1157 - val_loss: 2.0543\n",
      "Epoch 10/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1297 - loss: 2.0599 - val_accuracy: 0.1157 - val_loss: 2.0534\n",
      "Epoch 11/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1305 - loss: 2.0636 - val_accuracy: 0.1157 - val_loss: 2.0524\n",
      "Epoch 12/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.1476 - loss: 2.0643 - val_accuracy: 0.1157 - val_loss: 2.0527\n",
      "Epoch 13/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1350 - loss: 2.0715 - val_accuracy: 0.1157 - val_loss: 2.0507\n",
      "Epoch 14/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.1420 - loss: 2.0600 - val_accuracy: 0.1157 - val_loss: 2.0518\n",
      "Epoch 15/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.1306 - loss: 2.0752 - val_accuracy: 0.1157 - val_loss: 2.0521\n",
      "Epoch 16/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.1440 - loss: 2.0613 - val_accuracy: 0.1157 - val_loss: 2.0522\n",
      "Epoch 17/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.1405 - loss: 2.0612 - val_accuracy: 0.1157 - val_loss: 2.0517\n",
      "Epoch 18/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.1474 - loss: 2.0611 - val_accuracy: 0.1157 - val_loss: 2.0501\n",
      "Epoch 19/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.1550 - loss: 2.0730 - val_accuracy: 0.1157 - val_loss: 2.0533\n",
      "Epoch 20/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.1449 - loss: 2.0650 - val_accuracy: 0.1157 - val_loss: 2.0509\n",
      "Epoch 21/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.1543 - loss: 2.0688 - val_accuracy: 0.1157 - val_loss: 2.0488\n",
      "Epoch 22/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.1367 - loss: 2.0651 - val_accuracy: 0.1157 - val_loss: 2.0509\n",
      "Epoch 23/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.1562 - loss: 2.0634 - val_accuracy: 0.1157 - val_loss: 2.0515\n",
      "Epoch 24/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.1431 - loss: 2.0591 - val_accuracy: 0.1157 - val_loss: 2.0509\n",
      "Epoch 25/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.1554 - loss: 2.0679 - val_accuracy: 0.1157 - val_loss: 2.0520\n",
      "Epoch 26/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.1435 - loss: 2.0608 - val_accuracy: 0.1157 - val_loss: 2.0503\n",
      "Epoch 27/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.1430 - loss: 2.0598 - val_accuracy: 0.1157 - val_loss: 2.0512\n",
      "Epoch 28/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.1430 - loss: 2.0664 - val_accuracy: 0.1157 - val_loss: 2.0511\n",
      "Epoch 29/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.1406 - loss: 2.0605 - val_accuracy: 0.1157 - val_loss: 2.0515\n",
      "Epoch 30/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.1450 - loss: 2.0732 - val_accuracy: 0.1157 - val_loss: 2.0526\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1040 - loss: 2.0631\n",
      "Test Accuracy: 9.72%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\admin\\AppData\\Local\\Temp\\tmpp4fttteq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\admin\\AppData\\Local\\Temp\\tmpp4fttteq\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\admin\\AppData\\Local\\Temp\\tmpp4fttteq'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 59, 1), dtype=tf.float32, name='keras_tensor_9')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1681985217424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985217808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985218000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985218960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985219152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985219728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985219920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985220496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985220112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985220688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985219344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985222032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985221648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985222800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985216656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985223760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1681985223184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "Variable constant folding is failed. Please consider using enabling `experimental_enable_resource_variables` flag in the TFLite converter object. For example, converter.experimental_enable_resource_variables = True<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/lstm_1_1/TensorArrayV2_1@__inference_function_25578\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_25657\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/lstm_1_1/TensorArrayV2_1@__inference_function_25578\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_25657\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 132\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Convert to TensorFlow Lite for deployment\u001b[39;00m\n\u001b[0;32m    131\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n\u001b[1;32m--> 132\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_classification_model.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    135\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(tflite_model)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1231\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1230\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1231\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1183\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[0;32m   1182\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[1;32m-> 1183\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1744\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;129m@_export_metrics\u001b[39m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a keras model based on instance variables.\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m \n\u001b[0;32m   1735\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;124;03m      Invalid quantization parameters.\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1744\u001b[0m   saved_model_convert_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_as_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[0;32m   1746\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1725\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1721\u001b[0m   graph_def, input_tensors, output_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1722\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_keras_to_saved_model(temp_dir)\n\u001b[0;32m   1723\u001b[0m   )\n\u001b[0;32m   1724\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_dir:\n\u001b[1;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTFLiteKerasModelConverterV2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_tensors\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1729\u001b[0m   shutil\u001b[38;5;241m.\u001b[39mrmtree(temp_dir, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1466\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m   1459\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1460\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing new converter: If you encounter a problem \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1461\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease file a bug. You can opt-out \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1462\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby setting experimental_new_converter=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;66;03m# Converts model.\u001b[39;00m\n\u001b[1;32m-> 1466\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_graphdef\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconverter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_tflite_model(\n\u001b[0;32m   1474\u001b[0m     result,\n\u001b[0;32m   1475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quant_mode,\n\u001b[0;32m   1476\u001b[0m     _build_conversion_flags(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconverter_kwargs)\u001b[38;5;241m.\u001b[39mdebug_options,\n\u001b[0;32m   1477\u001b[0m     quant_io\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_new_quantizer,\n\u001b[0;32m   1478\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:212\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     report_error_message(\u001b[38;5;28mstr\u001b[39m(converter_error))\n\u001b[1;32m--> 212\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m converter_error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Re-throws the exception.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:1014\u001b[0m, in \u001b[0;36mconvert_graphdef\u001b[1;34m(input_data, input_tensors, output_tensors, **kwargs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m     model_flags\u001b[38;5;241m.\u001b[39moutput_arrays\u001b[38;5;241m.\u001b[39mappend(util\u001b[38;5;241m.\u001b[39mget_tensor_name(output_tensor))\n\u001b[1;32m-> 1014\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconversion_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug_info_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_mlir_converter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_mlir_converter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:376\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(model_flags, conversion_flags, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    368\u001b[0m         conversion_flags\u001b[38;5;241m.\u001b[39mguarantee_all_funcs_one_use \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    369\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m convert(\n\u001b[0;32m    370\u001b[0m             model_flags,\n\u001b[0;32m    371\u001b[0m             conversion_flags,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m             enable_mlir_converter,\n\u001b[0;32m    375\u001b[0m         )\n\u001b[1;32m--> 376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converter_error\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _run_deprecated_conversion_binary(\n\u001b[0;32m    379\u001b[0m     model_flags\u001b[38;5;241m.\u001b[39mSerializeToString(),\n\u001b[0;32m    380\u001b[0m     conversion_flags\u001b[38;5;241m.\u001b[39mSerializeToString(),\n\u001b[0;32m    381\u001b[0m     input_data_str,\n\u001b[0;32m    382\u001b[0m     debug_info_str,\n\u001b[0;32m    383\u001b[0m )\n",
      "\u001b[1;31mConverterError\u001b[0m: Variable constant folding is failed. Please consider using enabling `experimental_enable_resource_variables` flag in the TFLite converter object. For example, converter.experimental_enable_resource_variables = True<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/lstm_1_1/TensorArrayV2_1@__inference_function_25578\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_25657\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/lstm_1_1/TensorArrayV2_1@__inference_function_25578\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_25657\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# **Step 1: Data Preprocessing**\n",
    "DATA_PATH = \"C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/\"\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"Extract audio features (MFCCs, Chroma, Spectral Contrast).\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=16000)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        return np.hstack([mfccs.mean(axis=1), chroma.mean(axis=1), spectral_contrast.mean(axis=1)])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_emotion_from_filename(filename):\n",
    "    \"\"\"Extract emotion label from filename and map to zero-based indexing.\"\"\"\n",
    "    parts = filename.split('-')\n",
    "    emotion_code = int(parts[2])  # Extract emotion code\n",
    "    return emotion_code - 1  # Convert to zero-based index\n",
    "\n",
    "# Process all actor folders\n",
    "data = []\n",
    "for actor_folder in os.listdir(DATA_PATH):\n",
    "    folder_path = os.path.join(DATA_PATH, actor_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                features = extract_features(file_path)\n",
    "                if features is not None:\n",
    "                    label = parse_emotion_from_filename(file)\n",
    "                    data.append((features, label))\n",
    "\n",
    "# Create DataFrame\n",
    "features_df = pd.DataFrame(data, columns=[\"features\", \"label\"])\n",
    "\n",
    "# Convert features and labels into arrays\n",
    "X = np.array(features_df[\"features\"].tolist())\n",
    "y = np.array(features_df[\"label\"].tolist())\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reshape for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# **Step 2: Define the Model**\n",
    "def build_transformer_lstm(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Masking()(inputs)\n",
    "\n",
    "    # Transformer Encoder\n",
    "    x = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "    # LSTM Layer\n",
    "    x = layers.LSTM(128, return_sequences=False)(x)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "num_classes = len(np.unique(y))  # Number of unique emotion labels\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "model = build_transformer_lstm(input_shape, num_classes)\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# **Step 3: Train the Model**\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# **Step 4: Evaluate the Model**\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# **Step 5: Visualize Training Progress**\n",
    "# Accuracy Plot\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Loss Plot\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# **Step 6: Save the Model**\n",
    "model.save(\"emotion_classification_model.h5\")\n",
    "\n",
    "# Convert to TensorFlow Lite for deployment\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"emotion_classification_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff32e8-12b3-4549-8375-f918e8253965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211a22a3-867b-4ca9-9a59-9ff10ec52d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">897</span> │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ multi_head_attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any_1 (\u001b[38;5;33mAny\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m897\u001b[0m │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m2\u001b[0m │ multi_head_attention_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │           \u001b[38;5;34m1,032\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,004</span> (394.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,004\u001b[0m (394.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,004</span> (394.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,004\u001b[0m (394.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_6080\\2914167263.py\", line 120, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 2 5 5 3 7 4 3 6 5 2 5 4 6 7 6 0 3 2 2 2 3 2 6 2 7 1 2 1 1 3 1 4\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_11470]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 120\u001b[0m\n\u001b[0;32m    117\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# **Step 3: Train the Model**\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_val\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    126\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# **Step 4: Evaluate the Model**\u001b[39;00m\n\u001b[0;32m    129\u001b[0m test_loss, test_metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    130\u001b[0m     X_test, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: conf_test}, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_6080\\2914167263.py\", line 120, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 2 5 5 3 7 4 3 6 5 2 5 4 6 7 6 0 3 2 2 2 3 2 6 2 7 1 2 1 1 3 1 4\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_11470]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# **Step 1: Data Preprocessing**\n",
    "DATA_PATH = \"C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/\"\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"Extract audio features (MFCCs, Chroma, Spectral Contrast).\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=16000)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        return np.hstack([mfccs.mean(axis=1), chroma.mean(axis=1), spectral_contrast.mean(axis=1)])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_emotion_from_filename(filename):\n",
    "    \"\"\"Extract emotion label from filename and map to zero-based indexing.\"\"\"\n",
    "    parts = filename.split('-')\n",
    "    emotion_code = int(parts[2])  # Extract emotion code\n",
    "    return emotion_code - 1  # Convert to zero-based index\n",
    "\n",
    "# Generate synthetic confidence scores\n",
    "def generate_confidence(label):\n",
    "    \"\"\"Generate synthetic confidence scores based on the emotion label.\"\"\"\n",
    "    # For simplicity, assign higher confidence to certain labels (mock data)\n",
    "    confidence_map = {0: 0.9, 1: 0.8, 2: 0.85, 3: 0.7, 4: 0.95, 5: 0.75, 6: 0.88, 7: 0.92}\n",
    "    return confidence_map.get(label, 0.8)\n",
    "\n",
    "# Process all actor folders\n",
    "data = []\n",
    "for actor_folder in os.listdir(DATA_PATH):\n",
    "    folder_path = os.path.join(DATA_PATH, actor_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                features = extract_features(file_path)\n",
    "                if features is not None:\n",
    "                    label = parse_emotion_from_filename(file)\n",
    "                    confidence = generate_confidence(label)\n",
    "                    data.append((features, label, confidence))\n",
    "\n",
    "# Create DataFrame\n",
    "features_df = pd.DataFrame(data, columns=[\"features\", \"label\", \"confidence\"])\n",
    "\n",
    "# Convert features and labels into arrays\n",
    "X = np.array(features_df[\"features\"].tolist())\n",
    "y = np.array(features_df[\"label\"].tolist())\n",
    "confidence = np.array(features_df[\"confidence\"].tolist())\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_temp, y_train, y_temp, conf_train, conf_temp = train_test_split(\n",
    "    X, y, confidence, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test, conf_val, conf_test = train_test_split(\n",
    "    X_temp, y_temp, conf_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reshape for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Reshape confidence values to match model output\n",
    "conf_train = conf_train.reshape(-1, 1)  # Reshape to [batch_size, 1]\n",
    "conf_val = conf_val.reshape(-1, 1)\n",
    "conf_test = conf_test.reshape(-1, 1)\n",
    "\n",
    "# **Step 2: Define the Model**\n",
    "def build_transformer_lstm_with_confidence(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Masking()(inputs)\n",
    "\n",
    "    # Transformer Encoder\n",
    "    x = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "    # LSTM Layer\n",
    "    x = layers.LSTM(128, return_sequences=False)(x)\n",
    "\n",
    "    # Outputs\n",
    "    emotion_output = layers.Dense(num_classes, activation=\"softmax\", name=\"emotion_output\")(x)\n",
    "    confidence_output = layers.Dense(1, activation=\"sigmoid\", name=\"confidence_output\")(x)\n",
    "\n",
    "    model = models.Model(inputs, [emotion_output, confidence_output])\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "num_classes = len(np.unique(y))  # Number of unique emotion labels\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "model = build_transformer_lstm_with_confidence(input_shape, num_classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"emotion_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"confidence_output\": \"mse\"\n",
    "    },\n",
    "    metrics={\n",
    "        \"emotion_output\": \"accuracy\"\n",
    "    }\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# **Step 3: Train the Model**\n",
    "history = model.fit(\n",
    "    X_train, {\"emotion_output\": y_train, \"confidence_output\": conf_train},\n",
    "    validation_data=(X_val, {\"emotion_output\": y_val, \"confidence_output\": conf_val}),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# **Step 4: Evaluate the Model**\n",
    "test_loss, test_metrics = model.evaluate(\n",
    "    X_test, {\"emotion_output\": y_test, \"confidence_output\": conf_test}, verbose=1)\n",
    "print(f\"Test Emotion Accuracy: {test_metrics['emotion_output_accuracy'] * 100:.2f}%\")\n",
    "print(f\"Test Confidence MSE: {test_loss['confidence_output']:.4f}\")\n",
    "\n",
    "# **Step 5: Visualize Training Progress**\n",
    "# Accuracy Plot\n",
    "plt.plot(history.history['emotion_output_accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_emotion_output_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Emotion Classification Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Loss Plot\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Total Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# **Step 6: Save the Model**\n",
    "model.save(\"emotion_confidence_model.h5\")\n",
    "\n",
    "# Convert to TensorFlow Lite for deployment\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"emotion_confidence_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf58e2e9-a81f-4af2-a3df-11da8ceedf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the dataset: [0 1 2 3 4 5 6 7]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">897</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                               │                           │                 │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ any (\u001b[38;5;33mAny\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m897\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                               │                           │                 │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m2\u001b[0m │ multi_head_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ emotion_output (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                 │           \u001b[38;5;34m1,032\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ confidence_output (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,004</span> (394.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,004\u001b[0m (394.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,004</span> (394.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,004\u001b[0m (394.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18552\\1663889057.py\", line 123, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 4 2 5 2 1 2 1 1 5 4 6 4 7 5 5 3 2 2 3 5 5 5 6 0 0 6 1 0 2 3 3 4\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_5735]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 123\u001b[0m\n\u001b[0;32m    120\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# **Step 3: Train the Model**\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memotion_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfidence_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf_val\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    129\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# **Step 4: Evaluate the Model**\u001b[39;00m\n\u001b[0;32m    132\u001b[0m test_loss, test_metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    133\u001b[0m     X_test, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: conf_test}, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_18552\\1663889057.py\", line 123, in <module>\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 54, in train_step\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 398, in _compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 366, in compute_loss\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 618, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 659, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 60, in __call__\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 27, in call\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1870, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 1559, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 671, in sparse_categorical_crossentropy\n\nReceived a label value of 7 which is outside the valid range of [0, 1).  Label values: 4 2 5 2 1 2 1 1 5 4 6 4 7 5 5 3 2 2 3 5 5 5 6 0 0 6 1 0 2 3 3 4\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_one_step_on_iterator_5735]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# **Step 1: Data Preprocessing**\n",
    "DATA_PATH = \"C:/Users/admin/Desktop/Voice Expression Detection Model1/Giggle_Function_2/\"\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"Extract audio features (MFCCs, Chroma, Spectral Contrast).\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=16000)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        return np.hstack([mfccs.mean(axis=1), chroma.mean(axis=1), spectral_contrast.mean(axis=1)])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_emotion_from_filename(filename):\n",
    "    \"\"\"Extract emotion label from filename and map to zero-based indexing.\"\"\"\n",
    "    parts = filename.split('-')\n",
    "    emotion_code = int(parts[2])  # Extract emotion code\n",
    "    return emotion_code - 1  # Map to zero-based index\n",
    "\n",
    "# Generate synthetic confidence scores\n",
    "def generate_confidence(label):\n",
    "    \"\"\"Generate synthetic confidence scores based on the emotion label.\"\"\"\n",
    "    confidence_map = {0: 0.9, 1: 0.8, 2: 0.85, 3: 0.7, 4: 0.95, 5: 0.75, 6: 0.88, 7: 0.92}\n",
    "    return confidence_map.get(label, 0.8)\n",
    "\n",
    "# Process all actor folders\n",
    "data = []\n",
    "for actor_folder in os.listdir(DATA_PATH):\n",
    "    folder_path = os.path.join(DATA_PATH, actor_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                features = extract_features(file_path)\n",
    "                if features is not None:\n",
    "                    label = parse_emotion_from_filename(file)\n",
    "                    confidence = generate_confidence(label)\n",
    "                    data.append((features, label, confidence))\n",
    "\n",
    "# Create DataFrame\n",
    "features_df = pd.DataFrame(data, columns=[\"features\", \"label\", \"confidence\"])\n",
    "\n",
    "# Convert features and labels into arrays\n",
    "X = np.array(features_df[\"features\"].tolist())\n",
    "y = np.array(features_df[\"label\"].tolist())\n",
    "confidence = np.array(features_df[\"confidence\"].tolist())\n",
    "\n",
    "# Verify and assert label correctness\n",
    "num_classes = len(np.unique(y))\n",
    "print(f\"Unique labels in the dataset: {np.unique(y)}\")\n",
    "assert np.all((y >= 0) & (y < num_classes)), \"Labels must be in range [0, num_classes - 1]\"\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_temp, y_train, y_temp, conf_train, conf_temp = train_test_split(\n",
    "    X, y, confidence, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test, conf_val, conf_test = train_test_split(\n",
    "    X_temp, y_temp, conf_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reshape for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Reshape confidence values to match model output\n",
    "conf_train = conf_train.reshape(-1, 1)  # Reshape to [batch_size, 1]\n",
    "conf_val = conf_val.reshape(-1, 1)\n",
    "conf_test = conf_test.reshape(-1, 1)\n",
    "\n",
    "# **Step 2: Define the Model**\n",
    "def build_transformer_lstm_with_confidence(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Masking()(inputs)\n",
    "\n",
    "    # Transformer Encoder\n",
    "    x = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "    # LSTM Layer\n",
    "    x = layers.LSTM(128, return_sequences=False)(x)\n",
    "\n",
    "    # Outputs\n",
    "    emotion_output = layers.Dense(num_classes, activation=\"softmax\", name=\"emotion_output\")(x)\n",
    "    confidence_output = layers.Dense(1, activation=\"sigmoid\", name=\"confidence_output\")(x)\n",
    "\n",
    "    model = models.Model(inputs, [emotion_output, confidence_output])\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "model = build_transformer_lstm_with_confidence(input_shape, num_classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"emotion_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"confidence_output\": \"mse\"\n",
    "    },\n",
    "    metrics={\n",
    "        \"emotion_output\": \"accuracy\"\n",
    "    }\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# **Step 3: Train the Model**\n",
    "history = model.fit(\n",
    "    X_train, {\"emotion_output\": y_train, \"confidence_output\": conf_train},\n",
    "    validation_data=(X_val, {\"emotion_output\": y_val, \"confidence_output\": conf_val}),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# **Step 4: Evaluate the Model**\n",
    "test_loss, test_metrics = model.evaluate(\n",
    "    X_test, {\"emotion_output\": y_test, \"confidence_output\": conf_test}, verbose=1)\n",
    "print(f\"Test Emotion Accuracy: {test_metrics['emotion_output_accuracy'] * 100:.2f}%\")\n",
    "print(f\"Test Confidence MSE: {test_loss['confidence_output']:.4f}\")\n",
    "\n",
    "# **Step 5: Visualize Training Progress**\n",
    "# Accuracy Plot\n",
    "plt.plot(history.history['emotion_output_accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_emotion_output_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Emotion Classification Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Loss Plot\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Total Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# **Step 6: Save the Model**\n",
    "model.save(\"emotion_confidence_model.h5\")\n",
    "\n",
    "# Convert to TensorFlow Lite for deployment\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"emotion_confidence_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86075623-c5b8-4a12-a4fa-ec62126cae30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
